{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libraries:\n",
    "%load_ext autoreload\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from pymystem3 import Mystem\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import re\n",
    "import gensim.downloader as api\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_tfidf(documents):\n",
    "    dictionary = Dictionary(documents)\n",
    "    n_items = len(dictionary)\n",
    "    corpus = [dictionary.doc2bow(text) for text in documents]\n",
    "    tfidf = TfidfModel(corpus)\n",
    "    return tfidf[corpus], dictionary\n",
    "\n",
    "\n",
    "def get_tf_idf_counts(series):\n",
    "    tf_idf_flattened = [b for a in series for b in a if not type(a) == float]\n",
    "    counts = Counter(tf_idf_flattened)\n",
    "    return counts\n",
    "\n",
    "\n",
    "def get_top_words(corpus_tfidf, dictionary):\n",
    "    top_words_series = pd.Series(index=range(0,len(corpus_tfidf)))\n",
    "    top_words_series.name = 'tf_idf_words'\n",
    "    for i, row in enumerate(corpus_tfidf):\n",
    "        # sort the list\n",
    "        sorted_by_second = sorted(row, key=lambda tup: tup[1])\n",
    "        # get the top 20 elements\n",
    "        a = np.array(sorted_by_second[-20:], dtype=np.int32)\n",
    "        # get the first indices\n",
    "        idx = a[:,0].tolist()\n",
    "        #dictionary[a[:,0].tolist()]\n",
    "        article_top_words = [dictionary[i] for i in idx]\n",
    "        top_words_series.iloc[i] = article_top_words\n",
    "        \n",
    "    return top_words_series\n",
    "\n",
    "\n",
    "def output_wordcloud(counts, title = None, save_image = False):\n",
    "    cloud = WordCloud(stopwords=None, background_color='black', width=1200, height=900\n",
    "                     ).generate_from_frequencies(counts)\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    if title:\n",
    "        plt.title(title, fontsize=45)\n",
    "    plt.imshow(cloud)\n",
    "    plt.axis('off')\n",
    "    if save_image and title:\n",
    "        plt.savefig('generated_images/' + title + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "def print_yearly_wordclouds(tfidf_data, prefix):\n",
    "    for year in sorted(tfidf_data.year.unique()):\n",
    "        yearly_data = tfidf_data[tfidf_data['year'] == year].tf_idf_words\n",
    "        counts = get_tf_idf_counts(yearly_data)\n",
    "        title = prefix + str(year)\n",
    "        output_wordcloud(counts, title, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>lemmas_content</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaukasian konflikti: Aseissa Georgia ja Venäjä...</td>\n",
       "      <td>Kaukasian konflikti: Aseissa Georgia ja Venäjä...</td>\n",
       "      <td>2008-08-11T11:03:41+0300</td>\n",
       "      <td>[Kaukasia, konflikti, :, ase, Georg, ja, venäj...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Otteita Venäjän-tuntijoiden vastauksista</td>\n",
       "      <td>Otteita Venäjän-tuntijoiden vastauksista\\n\\nTä...</td>\n",
       "      <td>2007-01-14T12:46:58+0200</td>\n",
       "      <td>[ote, venäjä, vasta, tämä, tiivistelmä, olla, ...</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Etelä-Ossetian ruutitynnyri räjähti viimein</td>\n",
       "      <td>Etelä-Ossetian ruutitynnyri räjähti viimein\\n\\...</td>\n",
       "      <td>2008-08-12T21:33:32+0300</td>\n",
       "      <td>[Etelä-Ossetia, ruuti, räjähtää, viimein, perj...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yle Uutiset seuraa Ukrainan kriisiä hetki hetk...</td>\n",
       "      <td>Yle Uutiset seuraa Ukrainan kriisiä hetki hetk...</td>\n",
       "      <td>2014-03-18T09:06:59+0200</td>\n",
       "      <td>[Yle, uutinen, seura, ukraina, kriisi, hetki, ...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saksan ulkopolitiikan täyskäännös</td>\n",
       "      <td>Saksan ulkopolitiikan täyskäännös\\n\\nTuskin mi...</td>\n",
       "      <td>2014-10-02T12:30:30+0300</td>\n",
       "      <td>[saksa, ulko-, täyskäännös, tuska, mikään, muu...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Kaukasian konflikti: Aseissa Georgia ja Venäjä...   \n",
       "1           Otteita Venäjän-tuntijoiden vastauksista   \n",
       "2        Etelä-Ossetian ruutitynnyri räjähti viimein   \n",
       "3  Yle Uutiset seuraa Ukrainan kriisiä hetki hetk...   \n",
       "4                  Saksan ulkopolitiikan täyskäännös   \n",
       "\n",
       "                                             content  \\\n",
       "0  Kaukasian konflikti: Aseissa Georgia ja Venäjä...   \n",
       "1  Otteita Venäjän-tuntijoiden vastauksista\\n\\nTä...   \n",
       "2  Etelä-Ossetian ruutitynnyri räjähti viimein\\n\\...   \n",
       "3  Yle Uutiset seuraa Ukrainan kriisiä hetki hetk...   \n",
       "4  Saksan ulkopolitiikan täyskäännös\\n\\nTuskin mi...   \n",
       "\n",
       "              datePublished  \\\n",
       "0  2008-08-11T11:03:41+0300   \n",
       "1  2007-01-14T12:46:58+0200   \n",
       "2  2008-08-12T21:33:32+0300   \n",
       "3  2014-03-18T09:06:59+0200   \n",
       "4  2014-10-02T12:30:30+0300   \n",
       "\n",
       "                                      lemmas_content  year  \n",
       "0  [Kaukasia, konflikti, :, ase, Georg, ja, venäj...  2008  \n",
       "1  [ote, venäjä, vasta, tämä, tiivistelmä, olla, ...  2007  \n",
       "2  [Etelä-Ossetia, ruuti, räjähtää, viimein, perj...  2008  \n",
       "3  [Yle, uutinen, seura, ukraina, kriisi, hetki, ...  2014  \n",
       "4  [saksa, ulko-, täyskäännös, tuska, mikään, muu...  2014  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/processed/yle_fi_lemmas.csv', index_col = 0, converters = {'lemmas_content' : eval})\n",
    "data.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleanup.match('alude')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear lemmas from special characters:\n",
    "stop_words = stopwords.words('finnish') + list(string.punctuation) \n",
    "re_cleanup = re.compile('(^quot$|^lt$|^gt$|^II$|^\\/.*|^http.*|^ .*|^www|^-.*|.*[0-9].*|\\?|\\.|^\\&.*|.*-$|^lude$|^lisä$|\\\\n|^[A-Z]$|\\*|\\_|\\'|\\\"|\\`|nbsp|^.$|mdash|^Ag$|^Co|^Bank|Inc)', re.IGNORECASE)\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    filtered_sentence = [w.lower() for w in word_list if not w in stop_words and not re_cleanup.match(w)]\n",
    "    return filtered_sentence\n",
    "\n",
    "# Replace list - Putti - Putin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_lemmas = data.lemmas_content.apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.lemmas_content = cleaned_lemmas\n",
    "data.to_csv('data/processed/yle_fi_lemmas.csv', index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yle_fi_tfidf, yle_fi_dictionary = get_corpus_tfidf(data.lemmas_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_yle_fi = get_top_words(yle_fi_tfidf, yle_fi_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "yle_fi_tfidf = pd.concat([data['year'], top_words_yle_fi], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where tfidf is nan\n",
    "yle_fi_tfidf = yle_fi_tfidf.drop(yle_fi_tfidf[yle_fi_tfidf.tf_idf_words.isnull()].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where year is nan\n",
    "yle_fi_tfidf = yle_fi_tfidf.drop(yle_fi_tfidf[yle_fi_tfidf.year.isnull()].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast years to int\n",
    "yle_fi_tfidf.year = yle_fi_tfidf.year.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yle_fi_tfidf.to_csv('data/processed/yle_fi_tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "print_yearly_wordclouds() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c1992cc9391e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_yearly_wordclouds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myle_fi_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"YLE Finnish - \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: print_yearly_wordclouds() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "print_yearly_wordclouds(yle_fi_tfidf, \"YLE Finnish - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something broken in 2009\n",
    "prefix = \"YLE Finnish - \"\n",
    "tfidf_data = yle_fi_tfidf\n",
    "year = 2009\n",
    "yearly_data = tfidf_data[tfidf_data['year'] == year].tf_idf_words\n",
    "counts = get_tf_idf_counts(yearly_data)  \n",
    "title = prefix + str(year)\n",
    "output_wordcloud(counts, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2008-08-11T11:03:41+0300'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2008"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = yle_fi_local_lemmas\n",
    "col_names = ['headline','lead','content','datePublished','lemmas_content']\n",
    "data.columns = col_names\n",
    "datestring = data.iloc[0].datePublished\n",
    "datestring\n",
    "datetime.strptime(datestring[:10], '%Y-%m-%d').year\n",
    "data['year'] = data['datePublished'].apply(lambda s: datetime.strptime(s[:10], '%Y-%m-%d').year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(s):\n",
    "    year = None\n",
    "    try:\n",
    "        year = datetime.strptime(s[:10], '%Y-%m-%d').year\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['year'] = data['datePublished'].apply(extract_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[data['year'].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('lead', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/processed/yle_fi_lemmas.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tf-idf on yle_fi\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
