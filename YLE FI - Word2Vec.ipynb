{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libraries:\n",
    "%load_ext autoreload\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from pymystem3 import Mystem\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import re\n",
    "import gensim.downloader as api\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>lemmas_content</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Kaukasian konflikti: Aseissa Georgia ja Venäjä...</td>\n",
       "      <td>Kaukasian konflikti: Aseissa Georgia ja Venäjä...</td>\n",
       "      <td>2008-08-11T11:03:41+0300</td>\n",
       "      <td>[kaukasia, konflikti, ase, georg, venäjä, tuke...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Otteita Venäjän-tuntijoiden vastauksista</td>\n",
       "      <td>Otteita Venäjän-tuntijoiden vastauksista\\n\\nTä...</td>\n",
       "      <td>2007-01-14T12:46:58+0200</td>\n",
       "      <td>[ote, venäjä, vasta, tiivistelmä, koota, ote, ...</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Etelä-Ossetian ruutitynnyri räjähti viimein</td>\n",
       "      <td>Etelä-Ossetian ruutitynnyri räjähti viimein\\n\\...</td>\n",
       "      <td>2008-08-12T21:33:32+0300</td>\n",
       "      <td>[etelä-ossetia, ruuti, räjähtää, viimein, perj...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yle Uutiset seuraa Ukrainan kriisiä hetki hetk...</td>\n",
       "      <td>Yle Uutiset seuraa Ukrainan kriisiä hetki hetk...</td>\n",
       "      <td>2014-03-18T09:06:59+0200</td>\n",
       "      <td>[yle, uutinen, seura, ukraina, kriisi, hetki, ...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Saksan ulkopolitiikan täyskäännös</td>\n",
       "      <td>Saksan ulkopolitiikan täyskäännös\\n\\nTuskin mi...</td>\n",
       "      <td>2014-10-02T12:30:30+0300</td>\n",
       "      <td>[saksa, täyskäännös, tuska, mikään, muu, euroo...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           headline  \\\n",
       "0           0  Kaukasian konflikti: Aseissa Georgia ja Venäjä...   \n",
       "1           1           Otteita Venäjän-tuntijoiden vastauksista   \n",
       "2           2        Etelä-Ossetian ruutitynnyri räjähti viimein   \n",
       "3           3  Yle Uutiset seuraa Ukrainan kriisiä hetki hetk...   \n",
       "4           4                  Saksan ulkopolitiikan täyskäännös   \n",
       "\n",
       "                                             content  \\\n",
       "0  Kaukasian konflikti: Aseissa Georgia ja Venäjä...   \n",
       "1  Otteita Venäjän-tuntijoiden vastauksista\\n\\nTä...   \n",
       "2  Etelä-Ossetian ruutitynnyri räjähti viimein\\n\\...   \n",
       "3  Yle Uutiset seuraa Ukrainan kriisiä hetki hetk...   \n",
       "4  Saksan ulkopolitiikan täyskäännös\\n\\nTuskin mi...   \n",
       "\n",
       "              datePublished  \\\n",
       "0  2008-08-11T11:03:41+0300   \n",
       "1  2007-01-14T12:46:58+0200   \n",
       "2  2008-08-12T21:33:32+0300   \n",
       "3  2014-03-18T09:06:59+0200   \n",
       "4  2014-10-02T12:30:30+0300   \n",
       "\n",
       "                                      lemmas_content  year  \n",
       "0  [kaukasia, konflikti, ase, georg, venäjä, tuke...  2008  \n",
       "1  [ote, venäjä, vasta, tiivistelmä, koota, ote, ...  2007  \n",
       "2  [etelä-ossetia, ruuti, räjähtää, viimein, perj...  2008  \n",
       "3  [yle, uutinen, seura, ukraina, kriisi, hetki, ...  2014  \n",
       "4  [saksa, täyskäännös, tuska, mikään, muu, euroo...  2014  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/processed/yle_fi_lemmas.csv', converters = {'lemmas_content' : eval, 'lemmas_headline':eval})\n",
    "data.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-30 10:13:03,455 : INFO : collecting all words and their counts\n",
      "2018-05-30 10:13:03,460 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-05-30 10:13:04,002 : INFO : PROGRESS: at sentence #10000, processed 2297196 words, keeping 41429 word types\n",
      "2018-05-30 10:13:04,396 : INFO : PROGRESS: at sentence #20000, processed 4006068 words, keeping 66820 word types\n",
      "2018-05-30 10:13:04,769 : INFO : PROGRESS: at sentence #30000, processed 5683074 words, keeping 90594 word types\n",
      "2018-05-30 10:13:05,075 : INFO : PROGRESS: at sentence #40000, processed 7420611 words, keeping 115179 word types\n",
      "2018-05-30 10:13:05,403 : INFO : PROGRESS: at sentence #50000, processed 9166757 words, keeping 145130 word types\n",
      "2018-05-30 10:13:05,751 : INFO : PROGRESS: at sentence #60000, processed 11001060 words, keeping 168064 word types\n",
      "2018-05-30 10:13:06,060 : INFO : collected 185506 word types from a corpus of 12599269 raw words and 68472 sentences\n",
      "2018-05-30 10:13:06,061 : INFO : Loading a fresh vocabulary\n",
      "2018-05-30 10:13:09,447 : INFO : min_count=1 retains 185506 unique words (100% of original 185506, drops 0)\n",
      "2018-05-30 10:13:09,448 : INFO : min_count=1 leaves 12599269 word corpus (100% of original 12599269, drops 0)\n",
      "2018-05-30 10:13:10,093 : INFO : deleting the raw counts dictionary of 185506 items\n",
      "2018-05-30 10:13:10,105 : INFO : sample=0.001 downsamples 30 most-common words\n",
      "2018-05-30 10:13:10,106 : INFO : downsampling leaves estimated 12063191 word corpus (95.7% of prior 12599269)\n",
      "2018-05-30 10:13:11,121 : INFO : estimated required memory for 185506 words and 100 dimensions: 241157800 bytes\n",
      "2018-05-30 10:13:11,122 : INFO : resetting layer weights\n",
      "2018-05-30 10:13:13,442 : INFO : training model with 3 workers on 185506 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-05-30 10:13:14,456 : INFO : EPOCH 1 - PROGRESS: at 1.79% examples, 511337 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:15,457 : INFO : EPOCH 1 - PROGRESS: at 6.24% examples, 612005 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:16,469 : INFO : EPOCH 1 - PROGRESS: at 11.99% examples, 624634 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-30 10:13:17,469 : INFO : EPOCH 1 - PROGRESS: at 19.05% examples, 653659 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:13:18,475 : INFO : EPOCH 1 - PROGRESS: at 25.35% examples, 674318 words/s, in_qsize 5, out_qsize 1\n",
      "2018-05-30 10:13:19,479 : INFO : EPOCH 1 - PROGRESS: at 31.43% examples, 663235 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:20,510 : INFO : EPOCH 1 - PROGRESS: at 39.67% examples, 699755 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:21,529 : INFO : EPOCH 1 - PROGRESS: at 45.19% examples, 686572 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:13:22,554 : INFO : EPOCH 1 - PROGRESS: at 51.24% examples, 685965 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:23,613 : INFO : EPOCH 1 - PROGRESS: at 58.52% examples, 695919 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:24,629 : INFO : EPOCH 1 - PROGRESS: at 63.33% examples, 688519 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:13:25,646 : INFO : EPOCH 1 - PROGRESS: at 69.27% examples, 682375 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:26,662 : INFO : EPOCH 1 - PROGRESS: at 75.75% examples, 687330 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:27,667 : INFO : EPOCH 1 - PROGRESS: at 80.84% examples, 684642 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:28,676 : INFO : EPOCH 1 - PROGRESS: at 87.81% examples, 691883 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:29,717 : INFO : EPOCH 1 - PROGRESS: at 94.67% examples, 697570 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:30,712 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-30 10:13:30,716 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-30 10:13:30,720 : INFO : EPOCH 1 - PROGRESS: at 100.00% examples, 698164 words/s, in_qsize 0, out_qsize 1\n",
      "2018-05-30 10:13:30,721 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-30 10:13:30,722 : INFO : EPOCH - 1 : training on 12599269 raw words (12058018 effective words) took 17.3s, 698098 effective words/s\n",
      "2018-05-30 10:13:31,743 : INFO : EPOCH 2 - PROGRESS: at 3.03% examples, 729776 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:13:32,775 : INFO : EPOCH 2 - PROGRESS: at 7.69% examples, 690233 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:13:33,807 : INFO : EPOCH 2 - PROGRESS: at 13.67% examples, 672200 words/s, in_qsize 3, out_qsize 2\n",
      "2018-05-30 10:13:34,844 : INFO : EPOCH 2 - PROGRESS: at 20.82% examples, 694828 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:35,888 : INFO : EPOCH 2 - PROGRESS: at 25.96% examples, 669293 words/s, in_qsize 3, out_qsize 2\n",
      "2018-05-30 10:13:36,891 : INFO : EPOCH 2 - PROGRESS: at 32.81% examples, 671581 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:37,912 : INFO : EPOCH 2 - PROGRESS: at 37.54% examples, 652216 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:38,940 : INFO : EPOCH 2 - PROGRESS: at 42.41% examples, 638253 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:13:39,967 : INFO : EPOCH 2 - PROGRESS: at 49.01% examples, 649067 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:40,998 : INFO : EPOCH 2 - PROGRESS: at 55.96% examples, 659960 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:42,003 : INFO : EPOCH 2 - PROGRESS: at 61.57% examples, 662495 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:43,004 : INFO : EPOCH 2 - PROGRESS: at 67.84% examples, 665529 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-30 10:13:44,009 : INFO : EPOCH 2 - PROGRESS: at 73.60% examples, 663173 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:13:45,011 : INFO : EPOCH 2 - PROGRESS: at 79.31% examples, 668293 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:46,028 : INFO : EPOCH 2 - PROGRESS: at 83.98% examples, 661098 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:13:47,036 : INFO : EPOCH 2 - PROGRESS: at 89.30% examples, 657047 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:48,042 : INFO : EPOCH 2 - PROGRESS: at 94.40% examples, 653269 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:13:48,984 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-30 10:13:48,988 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-30 10:13:48,990 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-30 10:13:48,994 : INFO : EPOCH - 2 : training on 12599269 raw words (12057910 effective words) took 18.3s, 660138 effective words/s\n",
      "2018-05-30 10:13:50,008 : INFO : EPOCH 3 - PROGRESS: at 2.23% examples, 596892 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:51,011 : INFO : EPOCH 3 - PROGRESS: at 6.24% examples, 610142 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:52,018 : INFO : EPOCH 3 - PROGRESS: at 10.66% examples, 577962 words/s, in_qsize 3, out_qsize 2\n",
      "2018-05-30 10:13:53,028 : INFO : EPOCH 3 - PROGRESS: at 16.95% examples, 594128 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:54,030 : INFO : EPOCH 3 - PROGRESS: at 23.45% examples, 629984 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:55,035 : INFO : EPOCH 3 - PROGRESS: at 30.79% examples, 651520 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:56,100 : INFO : EPOCH 3 - PROGRESS: at 36.46% examples, 641427 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:57,105 : INFO : EPOCH 3 - PROGRESS: at 43.87% examples, 665475 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:13:58,154 : INFO : EPOCH 3 - PROGRESS: at 49.09% examples, 656078 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:13:59,198 : INFO : EPOCH 3 - PROGRESS: at 54.31% examples, 645854 words/s, in_qsize 6, out_qsize 2\n",
      "2018-05-30 10:14:00,204 : INFO : EPOCH 3 - PROGRESS: at 60.26% examples, 650706 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:01,205 : INFO : EPOCH 3 - PROGRESS: at 66.47% examples, 657855 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:02,238 : INFO : EPOCH 3 - PROGRESS: at 72.56% examples, 656643 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:03,251 : INFO : EPOCH 3 - PROGRESS: at 78.29% examples, 661646 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:04,286 : INFO : EPOCH 3 - PROGRESS: at 83.56% examples, 658493 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-30 10:14:05,288 : INFO : EPOCH 3 - PROGRESS: at 89.93% examples, 661862 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-30 10:14:06,289 : INFO : EPOCH 3 - PROGRESS: at 97.20% examples, 674427 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:06,736 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-30 10:14:06,746 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-30 10:14:06,755 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-30 10:14:06,756 : INFO : EPOCH - 3 : training on 12599269 raw words (12057659 effective words) took 17.8s, 678974 effective words/s\n",
      "2018-05-30 10:14:07,768 : INFO : EPOCH 4 - PROGRESS: at 2.32% examples, 616218 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:08,785 : INFO : EPOCH 4 - PROGRESS: at 7.09% examples, 661586 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:09,805 : INFO : EPOCH 4 - PROGRESS: at 12.78% examples, 646766 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:10,829 : INFO : EPOCH 4 - PROGRESS: at 18.43% examples, 625111 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:14:11,892 : INFO : EPOCH 4 - PROGRESS: at 24.55% examples, 641380 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:12,912 : INFO : EPOCH 4 - PROGRESS: at 31.21% examples, 646888 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:13,917 : INFO : EPOCH 4 - PROGRESS: at 36.62% examples, 639034 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:14,923 : INFO : EPOCH 4 - PROGRESS: at 41.63% examples, 631617 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-30 10:14:15,933 : INFO : EPOCH 4 - PROGRESS: at 48.55% examples, 647457 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:16,958 : INFO : EPOCH 4 - PROGRESS: at 53.86% examples, 640326 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-30 10:14:17,960 : INFO : EPOCH 4 - PROGRESS: at 59.57% examples, 643268 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:18,962 : INFO : EPOCH 4 - PROGRESS: at 63.66% examples, 633845 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:19,996 : INFO : EPOCH 4 - PROGRESS: at 68.69% examples, 624317 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-30 10:14:21,012 : INFO : EPOCH 4 - PROGRESS: at 73.97% examples, 621271 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:22,013 : INFO : EPOCH 4 - PROGRESS: at 78.25% examples, 617563 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:23,037 : INFO : EPOCH 4 - PROGRESS: at 83.02% examples, 614288 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:24,094 : INFO : EPOCH 4 - PROGRESS: at 88.43% examples, 612620 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-30 10:14:25,142 : INFO : EPOCH 4 - PROGRESS: at 93.85% examples, 611704 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-30 10:14:26,183 : INFO : EPOCH 4 - PROGRESS: at 98.64% examples, 611477 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:26,471 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-30 10:14:26,474 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-30 10:14:26,478 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-30 10:14:26,479 : INFO : EPOCH - 4 : training on 12599269 raw words (12056904 effective words) took 19.7s, 611436 effective words/s\n",
      "2018-05-30 10:14:27,516 : INFO : EPOCH 5 - PROGRESS: at 2.23% examples, 583973 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:28,563 : INFO : EPOCH 5 - PROGRESS: at 5.23% examples, 519949 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:14:29,576 : INFO : EPOCH 5 - PROGRESS: at 10.56% examples, 561228 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-30 10:14:30,579 : INFO : EPOCH 5 - PROGRESS: at 17.04% examples, 586832 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:31,580 : INFO : EPOCH 5 - PROGRESS: at 21.11% examples, 568460 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-30 10:14:32,595 : INFO : EPOCH 5 - PROGRESS: at 26.74% examples, 578767 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:33,611 : INFO : EPOCH 5 - PROGRESS: at 34.39% examples, 605975 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:14:34,629 : INFO : EPOCH 5 - PROGRESS: at 41.88% examples, 636550 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:35,653 : INFO : EPOCH 5 - PROGRESS: at 46.82% examples, 624482 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:36,689 : INFO : EPOCH 5 - PROGRESS: at 51.79% examples, 617558 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:37,727 : INFO : EPOCH 5 - PROGRESS: at 57.98% examples, 623113 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:14:38,740 : INFO : EPOCH 5 - PROGRESS: at 62.80% examples, 622551 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:14:39,743 : INFO : EPOCH 5 - PROGRESS: at 67.98% examples, 617544 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:40,747 : INFO : EPOCH 5 - PROGRESS: at 74.64% examples, 627303 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-30 10:14:41,750 : INFO : EPOCH 5 - PROGRESS: at 79.92% examples, 630683 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:42,765 : INFO : EPOCH 5 - PROGRESS: at 84.35% examples, 623614 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:14:43,813 : INFO : EPOCH 5 - PROGRESS: at 88.43% examples, 612839 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:44,818 : INFO : EPOCH 5 - PROGRESS: at 93.20% examples, 609226 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-30 10:14:45,818 : INFO : EPOCH 5 - PROGRESS: at 98.93% examples, 616286 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-30 10:14:46,011 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-30 10:14:46,025 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-30 10:14:46,039 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-30 10:14:46,040 : INFO : EPOCH - 5 : training on 12599269 raw words (12058300 effective words) took 19.6s, 616575 effective words/s\n",
      "2018-05-30 10:14:46,041 : INFO : training on a 62996345 raw words (60288791 effective words) took 92.6s, 651081 effective words/s\n"
     ]
    }
   ],
   "source": [
    "sentences = data.lemmas_content\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('länsi', 0.6412229537963867),\n",
       " ('itä', 0.5725439786911011),\n",
       " ('suurvalta', 0.5677061080932617),\n",
       " ('vīcīna', 0.5491490364074707),\n",
       " ('venäjä', 0.5239830613136292),\n",
       " ('vihollinen', 0.515234649181366),\n",
       " ('toisaalta', 0.5106375813484192),\n",
       " ('lähialue', 0.49187231063842773),\n",
       " ('viha', 0.4911051392555237),\n",
       " ('suhde', 0.4877402186393738)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['naapuri'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('yhdysvallat', 0.7446652054786682),\n",
       " ('kiina', 0.6143582463264465),\n",
       " ('kanada', 0.6052343249320984),\n",
       " ('japani', 0.5615869760513306),\n",
       " ('maa', 0.5432892441749573),\n",
       " ('valko-venäjä', 0.5337971448898315),\n",
       " ('suomia', 0.5253757238388062),\n",
       " ('ruotsi', 0.505166232585907),\n",
       " ('kuuba', 0.5051059126853943),\n",
       " ('isäntä', 0.48110100626945496),\n",
       " ('suomi', 0.4791686534881592),\n",
       " ('brasilia', 0.47670450806617737),\n",
       " ('iso-britannia', 0.47642916440963745),\n",
       " ('kazakstan', 0.46718963980674744),\n",
       " ('etelä-korea', 0.4633820950984955),\n",
       " ('australia', 0.45188766717910767),\n",
       " ('nigeria', 0.45019039511680603),\n",
       " ('tanska', 0.4425284266471863),\n",
       " ('saksa', 0.4422125518321991),\n",
       " ('jenkki', 0.43623030185699463),\n",
       " ('nhl-ryhmän', 0.43525123596191406),\n",
       " ('slovakia', 0.4347362220287323),\n",
       " ('etelä-afrikka', 0.4339946508407593),\n",
       " ('ranska', 0.43015986680984497),\n",
       " ('hallita', 0.42894017696380615)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['venäjä','usa']\n",
    "number_of_results = 25\n",
    "\n",
    "print(\"Nearest words:\")\n",
    "model.wv.most_similar(positive=words ,topn=number_of_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word similarity:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42047345716505585"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_compare = ('pietari', 'turku')\n",
    "\n",
    "print(\"Word similarity:\")\n",
    "model.wv.similarity(*words_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector math:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('republikaani', 0.6388195753097534),\n",
       " ('esivaali', 0.5393120050430298),\n",
       " ('republikaaninen', 0.5293186902999878),\n",
       " ('parlamentarismi', 0.5172135829925537),\n",
       " ('ihanne', 0.511397659778595)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_terms = ['suomi', 'demokraatti']\n",
    "negative_terms = ['venäjä']\n",
    "\n",
    "print(\"Vector math:\")\n",
    "model.wv.most_similar(positive=positive_terms, negative=negative_terms, topn=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finland_russia",
   "language": "python",
   "name": "finland_russia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
