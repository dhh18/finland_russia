def import_yle_fi():
    # Original columns:
    #text - keep
    #analyzedText - drop
    #url - drop
    #publisher - drop
    #coverage - drop
    #timePublished - keep
    #headline - keep
    #score - drop
    #lead - keep

    analyzed_file_location = '/var/www/html/work/compressed/data/russia_finland/analyzed/yle_finnish_mentioning_russia_0.json'
    yle_fi_raw = None
    with open(analyzed_file_location,  encoding='utf-8') as json_data:
        yle_fi_raw = json_data.read().replace('}\n{', '},\n{')

    yle_fi_dict = json.loads(yle_fi_raw)

    yle_fi_data = pd.DataFrame.from_dict(yle_fi_dict['results']['docs'])

    drop_list = ['url', 'publisher', 'coverage', 'score']

    yle_fi_data = yle_fi_data.drop(columns = drop_list)

    return yle_fi_data

data = import_yle_fi()

# Store the output in CSV

#yle_fi_data.iloc[:5]

#yle_fi_data.to_csv('/var/www/html/work/compressed/data/russia_finland/processed/yle_fi_processed.csv')

###

# create a new pandas column called "lemmatized" by making lists of lemmas from analyzedText column

###

data.iloc[0]['analyzedText']

###

lemmatized = data.iloc[:5]['analyzedText'].apply(
        lambda s: [a['analysis'][0]['wordParts'][0]['lemma'] for a in s[0]])
lemmatized

###

lemmatized[0]

###

x = data.iloc[0]['analyzedText']

###

def get_lemmas(cell):
    lemma_list = []
    for chapter in cell:
        for sentence in chapter:
            for word in sentence:
                lemma = word['analysis'][0]['wordParts'][0]['lemma']
                if not lemma == ' ':
                    lemma_list.append(lemma)

    return lemma_list

###

def get_lemmas(cell):
    lemma_list = []
#    print(cell[0][0][0]['analysis'][0]['wordParts'][0]['lemma'])
    for sentence in cell:
        for word in sentence:
            lemma = word['analysis'][0]['wordParts'][0]['lemma']
            if not lemma == ' ':
                lemma_list.append(lemma)

    return lemma_list


def lemmatize_yle_fi_data(data):

    data['lemmas_content'] = data['analyzedText'].apply(
        lambda s:[a['analysis'][0]['wordParts'][0]['lemma'] for a in s[0]])

    #drop_list = ['url', 'publisher', 'coverage', 'score']

    #data = data.drop(columns = drop_list)

    return data

yle_fi_data_lemmatized = lemmatize_yle_fi_data(data)

# Store the output in CSV

###

yle_fi_data_lemmatized.iloc[:100]

###

foo = yle_fi_data.iloc[0]['analyzedText']
foo

###

for el in foo:
    print(el['analysis'][0]['wordParts'][0]['lemma'])

###

foo[0][0]['analysis']

#############################################################

def import_yle_fi():
    # Original columns:
    #text - keep
    #analyzedText - drop
    #url - drop
    #publisher - drop
    #coverage - drop
    #timePublished - keep
    #headline - keep
    #score - drop
    #lead - keep

    analyzed_file_location = '/var/www/html/work/compressed/data/russia_finland/analyzed/yle_finnish_mentioning_russia_0.json'
    yle_fi_raw = None
    with open(analyzed_file_location,  encoding='utf-8') as json_data:
        yle_fi_raw = json_data.read().replace('}\n{', '},\n{')

    yle_fi_dict = json.loads(yle_fi_raw)

    yle_fi_data = pd.DataFrame.from_dict(yle_fi_dict['results']['docs'])

    drop_list = ['url', 'publisher', 'coverage', 'score']

    yle_fi_data = yle_fi_data.drop(columns = drop_list)

    return yle_fi_data

yle_fi_data = import_yle_fi()

# Store the output in CSV

#yle_fi_data.iloc[:5]

#yle_fi_data.to_csv('/var/www/html/work/compressed/data/russia_finland/processed/yle_fi_processed.csv')

# create a new pandas column called "lemmatized" by making lists of lemmas from analyzedText column

def import_yle_fi_lemmatized():
    data = yle_fi_data

    data['analyzedText'] = data['analyzedText'].apply(lambda s:[a['analysis']['wordParts']['lemma'] for a in s])

    drop_list = ['url', 'publisher', 'coverage', 'score']

    data = data.drop(columns = drop_list)

    return data

yle_fi_data_lemmatized = import_yle_fi_lemmatized()

# Store the output in CSV

yle_fi_data.iloc[:6]
