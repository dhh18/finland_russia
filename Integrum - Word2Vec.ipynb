{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# System libraries:\n",
    "%load_ext autoreload\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from pymystem3 import Mystem\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import re\n",
    "import gensim.downloader as api\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrum_local_lemmas = pd.read_csv('data/processed/integrum_local_lemmas.csv', converters = {'lemmas_content' : eval, 'lemmas_headline':eval})\n",
    "integrum_federal_lemmas = pd.read_csv('data/processed/integrum_federal_lemmas.csv', converters = {'lemmas_content' : eval, 'lemmas_headline':eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 13:18:55,674 : INFO : collecting all words and their counts\n",
      "2018-05-29 13:18:55,677 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-05-29 13:18:56,890 : INFO : PROGRESS: at sentence #10000, processed 3849812 words, keeping 95908 word types\n",
      "2018-05-29 13:18:58,555 : INFO : PROGRESS: at sentence #20000, processed 8794850 words, keeping 138728 word types\n",
      "2018-05-29 13:19:00,097 : INFO : PROGRESS: at sentence #30000, processed 13515149 words, keeping 177293 word types\n",
      "2018-05-29 13:19:01,315 : INFO : collected 201515 word types from a corpus of 16945329 raw words and 36017 sentences\n",
      "2018-05-29 13:19:01,316 : INFO : Loading a fresh vocabulary\n",
      "2018-05-29 13:19:04,089 : INFO : min_count=1 retains 201515 unique words (100% of original 201515, drops 0)\n",
      "2018-05-29 13:19:04,090 : INFO : min_count=1 leaves 16945329 word corpus (100% of original 16945329, drops 0)\n",
      "2018-05-29 13:19:04,740 : INFO : deleting the raw counts dictionary of 201515 items\n",
      "2018-05-29 13:19:04,760 : INFO : sample=0.001 downsamples 15 most-common words\n",
      "2018-05-29 13:19:04,761 : INFO : downsampling leaves estimated 16251288 word corpus (95.9% of prior 16945329)\n",
      "2018-05-29 13:19:05,957 : INFO : estimated required memory for 201515 words and 100 dimensions: 261969500 bytes\n",
      "2018-05-29 13:19:05,959 : INFO : resetting layer weights\n",
      "2018-05-29 13:19:08,604 : INFO : training model with 3 workers on 201515 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-05-29 13:19:09,617 : INFO : EPOCH 1 - PROGRESS: at 6.79% examples, 728603 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:10,622 : INFO : EPOCH 1 - PROGRESS: at 14.94% examples, 813240 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:11,640 : INFO : EPOCH 1 - PROGRESS: at 21.48% examples, 828203 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:12,643 : INFO : EPOCH 1 - PROGRESS: at 25.89% examples, 835058 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:13,648 : INFO : EPOCH 1 - PROGRESS: at 31.06% examples, 836253 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:14,666 : INFO : EPOCH 1 - PROGRESS: at 35.59% examples, 839445 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:15,669 : INFO : EPOCH 1 - PROGRESS: at 41.07% examples, 840823 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:16,673 : INFO : EPOCH 1 - PROGRESS: at 46.13% examples, 841906 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:17,683 : INFO : EPOCH 1 - PROGRESS: at 51.61% examples, 843581 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:18,683 : INFO : EPOCH 1 - PROGRESS: at 56.54% examples, 843329 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:19,701 : INFO : EPOCH 1 - PROGRESS: at 63.24% examples, 838836 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:20,720 : INFO : EPOCH 1 - PROGRESS: at 69.88% examples, 840477 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-29 13:19:21,730 : INFO : EPOCH 1 - PROGRESS: at 74.32% examples, 837088 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:22,732 : INFO : EPOCH 1 - PROGRESS: at 78.40% examples, 836346 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:23,745 : INFO : EPOCH 1 - PROGRESS: at 82.17% examples, 831233 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-29 13:19:24,745 : INFO : EPOCH 1 - PROGRESS: at 86.13% examples, 826712 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:25,756 : INFO : EPOCH 1 - PROGRESS: at 90.54% examples, 826245 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:26,776 : INFO : EPOCH 1 - PROGRESS: at 94.69% examples, 826602 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:27,777 : INFO : EPOCH 1 - PROGRESS: at 98.74% examples, 829208 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:28,069 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 13:19:28,082 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 13:19:28,089 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 13:19:28,090 : INFO : EPOCH - 1 : training on 16945329 raw words (16157209 effective words) took 19.5s, 829408 effective words/s\n",
      "2018-05-29 13:19:29,108 : INFO : EPOCH 2 - PROGRESS: at 6.91% examples, 742584 words/s, in_qsize 3, out_qsize 2\n",
      "2018-05-29 13:19:30,115 : INFO : EPOCH 2 - PROGRESS: at 14.87% examples, 805430 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:31,119 : INFO : EPOCH 2 - PROGRESS: at 21.48% examples, 829889 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:32,139 : INFO : EPOCH 2 - PROGRESS: at 26.12% examples, 843750 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-29 13:19:33,144 : INFO : EPOCH 2 - PROGRESS: at 31.39% examples, 847188 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:34,144 : INFO : EPOCH 2 - PROGRESS: at 35.82% examples, 846334 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:35,159 : INFO : EPOCH 2 - PROGRESS: at 41.27% examples, 844142 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-29 13:19:36,160 : INFO : EPOCH 2 - PROGRESS: at 46.55% examples, 850986 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:37,171 : INFO : EPOCH 2 - PROGRESS: at 52.06% examples, 851277 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:38,177 : INFO : EPOCH 2 - PROGRESS: at 57.09% examples, 849988 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:39,194 : INFO : EPOCH 2 - PROGRESS: at 63.90% examples, 845565 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:40,197 : INFO : EPOCH 2 - PROGRESS: at 69.88% examples, 841085 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:41,204 : INFO : EPOCH 2 - PROGRESS: at 74.54% examples, 840578 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:42,205 : INFO : EPOCH 2 - PROGRESS: at 78.57% examples, 839694 words/s, in_qsize 5, out_qsize 1\n",
      "2018-05-29 13:19:43,217 : INFO : EPOCH 2 - PROGRESS: at 82.74% examples, 840756 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-29 13:19:44,243 : INFO : EPOCH 2 - PROGRESS: at 86.99% examples, 835708 words/s, in_qsize 3, out_qsize 2\n",
      "2018-05-29 13:19:45,278 : INFO : EPOCH 2 - PROGRESS: at 91.21% examples, 831016 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:46,279 : INFO : EPOCH 2 - PROGRESS: at 95.72% examples, 836800 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:47,299 : INFO : EPOCH 2 - PROGRESS: at 99.75% examples, 838329 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:47,335 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 13:19:47,343 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 13:19:47,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 13:19:47,359 : INFO : EPOCH - 2 : training on 16945329 raw words (16156657 effective words) took 19.3s, 838674 effective words/s\n",
      "2018-05-29 13:19:48,369 : INFO : EPOCH 3 - PROGRESS: at 7.69% examples, 840372 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:49,390 : INFO : EPOCH 3 - PROGRESS: at 16.08% examples, 863277 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:50,403 : INFO : EPOCH 3 - PROGRESS: at 22.49% examples, 878268 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:51,419 : INFO : EPOCH 3 - PROGRESS: at 27.25% examples, 883385 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-29 13:19:52,437 : INFO : EPOCH 3 - PROGRESS: at 32.37% examples, 878712 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:53,457 : INFO : EPOCH 3 - PROGRESS: at 37.08% examples, 872870 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:54,471 : INFO : EPOCH 3 - PROGRESS: at 42.67% examples, 875254 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:55,471 : INFO : EPOCH 3 - PROGRESS: at 47.81% examples, 875607 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:56,476 : INFO : EPOCH 3 - PROGRESS: at 52.91% examples, 864147 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-29 13:19:57,483 : INFO : EPOCH 3 - PROGRESS: at 58.91% examples, 867634 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:58,501 : INFO : EPOCH 3 - PROGRESS: at 65.60% examples, 863106 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:19:59,502 : INFO : EPOCH 3 - PROGRESS: at 71.06% examples, 856012 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:00,513 : INFO : EPOCH 3 - PROGRESS: at 75.71% examples, 854912 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-29 13:20:01,513 : INFO : EPOCH 3 - PROGRESS: at 79.77% examples, 853289 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-29 13:20:02,520 : INFO : EPOCH 3 - PROGRESS: at 83.42% examples, 846625 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:03,523 : INFO : EPOCH 3 - PROGRESS: at 87.57% examples, 842384 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:04,533 : INFO : EPOCH 3 - PROGRESS: at 92.00% examples, 842434 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:05,562 : INFO : EPOCH 3 - PROGRESS: at 95.91% examples, 838682 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:06,571 : INFO : EPOCH 3 - PROGRESS: at 99.55% examples, 835330 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:06,689 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 13:20:06,703 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 13:20:06,708 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 13:20:06,709 : INFO : EPOCH - 3 : training on 16945329 raw words (16156975 effective words) took 19.3s, 835195 effective words/s\n",
      "2018-05-29 13:20:07,720 : INFO : EPOCH 4 - PROGRESS: at 6.60% examples, 701913 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-29 13:20:08,746 : INFO : EPOCH 4 - PROGRESS: at 14.26% examples, 768225 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-29 13:20:09,749 : INFO : EPOCH 4 - PROGRESS: at 20.30% examples, 757172 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-29 13:20:10,771 : INFO : EPOCH 4 - PROGRESS: at 24.75% examples, 769243 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:11,780 : INFO : EPOCH 4 - PROGRESS: at 29.62% examples, 782285 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:12,785 : INFO : EPOCH 4 - PROGRESS: at 33.73% examples, 781187 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-29 13:20:13,796 : INFO : EPOCH 4 - PROGRESS: at 38.46% examples, 777714 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:14,801 : INFO : EPOCH 4 - PROGRESS: at 43.23% examples, 782365 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:15,806 : INFO : EPOCH 4 - PROGRESS: at 48.35% examples, 791884 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:16,809 : INFO : EPOCH 4 - PROGRESS: at 54.09% examples, 802786 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:17,810 : INFO : EPOCH 4 - PROGRESS: at 60.67% examples, 811360 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:18,818 : INFO : EPOCH 4 - PROGRESS: at 67.52% examples, 815006 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-29 13:20:19,822 : INFO : EPOCH 4 - PROGRESS: at 72.94% examples, 820158 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-29 13:20:20,841 : INFO : EPOCH 4 - PROGRESS: at 77.50% examples, 822632 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:21,849 : INFO : EPOCH 4 - PROGRESS: at 81.74% examples, 824738 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:22,863 : INFO : EPOCH 4 - PROGRESS: at 85.85% examples, 822661 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:23,869 : INFO : EPOCH 4 - PROGRESS: at 89.96% examples, 820144 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:24,875 : INFO : EPOCH 4 - PROGRESS: at 94.12% examples, 821050 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:25,879 : INFO : EPOCH 4 - PROGRESS: at 98.33% examples, 824012 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-29 13:20:26,295 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 13:20:26,301 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 13:20:26,317 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 13:20:26,318 : INFO : EPOCH - 4 : training on 16945329 raw words (16157487 effective words) took 19.6s, 824125 effective words/s\n",
      "2018-05-29 13:20:27,323 : INFO : EPOCH 5 - PROGRESS: at 7.10% examples, 779369 words/s, in_qsize 4, out_qsize 1\n",
      "2018-05-29 13:20:28,326 : INFO : EPOCH 5 - PROGRESS: at 14.42% examples, 788943 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:29,330 : INFO : EPOCH 5 - PROGRESS: at 20.71% examples, 788466 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:30,331 : INFO : EPOCH 5 - PROGRESS: at 25.00% examples, 792663 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:31,331 : INFO : EPOCH 5 - PROGRESS: at 30.11% examples, 807581 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:32,340 : INFO : EPOCH 5 - PROGRESS: at 34.78% examples, 819544 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:33,342 : INFO : EPOCH 5 - PROGRESS: at 40.19% examples, 823702 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:34,370 : INFO : EPOCH 5 - PROGRESS: at 44.99% examples, 820234 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:35,387 : INFO : EPOCH 5 - PROGRESS: at 49.47% examples, 812568 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:36,394 : INFO : EPOCH 5 - PROGRESS: at 54.74% examples, 815847 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:37,410 : INFO : EPOCH 5 - PROGRESS: at 61.94% examples, 824331 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-29 13:20:38,424 : INFO : EPOCH 5 - PROGRESS: at 68.91% examples, 829599 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:39,439 : INFO : EPOCH 5 - PROGRESS: at 74.17% examples, 835302 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:40,441 : INFO : EPOCH 5 - PROGRESS: at 78.45% examples, 837238 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-29 13:20:41,451 : INFO : EPOCH 5 - PROGRESS: at 82.74% examples, 840389 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:42,456 : INFO : EPOCH 5 - PROGRESS: at 87.08% examples, 837543 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-29 13:20:43,458 : INFO : EPOCH 5 - PROGRESS: at 91.46% examples, 836070 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-29 13:20:44,460 : INFO : EPOCH 5 - PROGRESS: at 95.55% examples, 836804 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-29 13:20:45,474 : INFO : EPOCH 5 - PROGRESS: at 99.38% examples, 835926 words/s, in_qsize 6, out_qsize 1\n",
      "2018-05-29 13:20:45,597 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-29 13:20:45,608 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-29 13:20:45,618 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-29 13:20:45,619 : INFO : EPOCH - 5 : training on 16945329 raw words (16156932 effective words) took 19.3s, 837282 effective words/s\n",
      "2018-05-29 13:20:45,620 : INFO : training on a 84726645 raw words (80785260 effective words) took 97.0s, 832710 effective words/s\n"
     ]
    }
   ],
   "source": [
    "sentences_local = integrum_local_lemmas.lemmas_content\n",
    "# train word2vec on the two sentences\n",
    "model_local = gensim.models.Word2Vec(sentences_local, min_count=1)\n",
    "\n",
    "sentences_federal = integrum_federal_lemmas.lemmas_content\n",
    "# train word2vec on the two sentences\n",
    "model_federal = gensim.models.Word2Vec(sentences_federal, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrum local:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('элкотека', 0.7536649107933044),\n",
       " ('синебрюхофф', 0.7445650696754456),\n",
       " ('дженерал', 0.7264657020568848),\n",
       " ('валмет', 0.7248556613922119),\n",
       " ('икеа', 0.7216954231262207),\n",
       " ('моторс', 0.71682208776474),\n",
       " ('фортум', 0.7142850756645203),\n",
       " ('пит', 0.7071996927261353),\n",
       " ('сименс', 0.7054600119590759),\n",
       " ('фазер', 0.7002048492431641),\n",
       " ('раутаруукка', 0.692550539970398),\n",
       " ('текс', 0.689965546131134),\n",
       " ('фудлайн', 0.6897444128990173),\n",
       " ('Metso', 0.684923529624939),\n",
       " ('хонк', 0.6811659336090088),\n",
       " ('электролюкс', 0.675460934638977),\n",
       " ('альстрем', 0.673250675201416),\n",
       " ('валио', 0.6728737354278564),\n",
       " ('апит', 0.6716701984405518),\n",
       " ('энсо', 0.6696405410766602),\n",
       " ('сведвуд', 0.6665652990341187),\n",
       " ('ExxonMobil', 0.6660447120666504),\n",
       " ('тойота', 0.6650810837745667),\n",
       " ('петмол', 0.6631209850311279),\n",
       " ('Daimler', 0.6601812839508057)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrum federal:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('валио', 0.7964282631874084),\n",
       " ('скартел', 0.7304878830909729),\n",
       " ('сименс', 0.7292211055755615),\n",
       " ('фольксваген', 0.7063729763031006),\n",
       " ('шкода', 0.6917002201080322),\n",
       " ('майкрософт', 0.69150710105896),\n",
       " ('оринимать', 0.6872502565383911),\n",
       " ('полипласт', 0.681629478931427),\n",
       " ('тальго', 0.6795402765274048),\n",
       " ('стрим', 0.6783123016357422),\n",
       " ('статойло', 0.6762619018554688),\n",
       " ('дженерал', 0.6755160093307495),\n",
       " ('норск', 0.6744836568832397),\n",
       " ('энерго', 0.6739196181297302),\n",
       " ('пежо', 0.6733487844467163),\n",
       " ('трансконтейнер', 0.6732388734817505),\n",
       " ('турпарад', 0.6689261794090271),\n",
       " ('нижнекамскшина', 0.6655929088592529),\n",
       " ('Valio', 0.6647659540176392),\n",
       " ('Teboil', 0.661560595035553),\n",
       " ('оверсиз', 0.6607126593589783),\n",
       " ('крост', 0.65885329246521),\n",
       " ('фортум', 0.6537583470344543),\n",
       " ('юниливер', 0.6536508798599243),\n",
       " ('акрон', 0.6534441709518433)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_positive = ['нокиа']\n",
    "number_of_results = 25\n",
    "\n",
    "print(\"Integrum local:\")\n",
    "model_local.wv.most_similar(positive=words_positive ,topn=number_of_results)\n",
    "\n",
    "print(\"Integrum federal:\")\n",
    "model_federal.wv.most_similar(positive=words_positive ,topn=number_of_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrum local similarity:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3859300666593514"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrum federal similarity:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19746752395392744"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_compare = ('финляндия', 'сша')\n",
    "\n",
    "print(\"Integrum local similarity:\")\n",
    "model_local.wv.similarity(*words_to_compare)\n",
    "\n",
    "print(\"Integrum federal similarity:\")\n",
    "model_federal.wv.similarity(*words_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrum local similarity:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('кухня', 0.529101550579071),\n",
       " ('душевой', 0.5201793909072876),\n",
       " ('туалет', 0.49875491857528687),\n",
       " ('парная', 0.4677061140537262),\n",
       " ('ванна', 0.46202588081359863)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrum federal similarity:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('баня', 0.5577921867370605),\n",
       " ('туалет', 0.5228835344314575),\n",
       " ('дорожка', 0.5196024775505066),\n",
       " ('одежда', 0.48897117376327515),\n",
       " ('развлечение', 0.48832979798316956)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_terms = ['россия','сауна']\n",
    "negative_terms = ['финляндия']\n",
    "\n",
    "print(\"Integrum local similarity:\")\n",
    "model_local.wv.most_similar(positive=positive_terms, negative=negative_terms, topn=5)\n",
    "\n",
    "print(\"Integrum federal similarity:\")\n",
    "model_federal.wv.most_similar(positive=positive_terms, negative=negative_terms, topn=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finland_russia",
   "language": "python",
   "name": "finland_russia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
